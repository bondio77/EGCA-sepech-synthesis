preprocessing:
  preprocessed_path: ""
  speakers: ["0011", "0012", "0013", "0014", "0015", "0016", "0017", "0018", "0019", "0020"]


model:
  hidden_dim: 256
  num_layers: 6
  num_emotions: 5
  emotion_embedding_dim: 256  # Emotion embedding dimension


training:
  batch_size: 32
  num_workers: 12
  learning_rate: 1.0e-6
  lr_step_size: 30
  lr_gamma: 0.1

  max_steps: 20000
  save_step: 1000
  eval_step: 200
  model_save_path: ""


  log_dir: "runs/emotion_intensity_experiment"

rank_model:
  alpha: 0.1
  beta: 1.0
  gamma: 1.0
  delta: 0.1
